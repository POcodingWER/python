{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🔥 PyTorch 기초 - Week 1 Day 1\n",
        "\n",
        "## 📋 학습 목표\n",
        "1. **PyTorch 설치 확인** ✅\n",
        "2. **Tensor 기본 연산** 🎯\n",
        "3. **autograd 자동 미분** 🧠\n",
        "4. **첫 신경망 구현** 🚀\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎯 Step 1: PyTorch 설치 확인\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔥 PyTorch 버전: 2.8.0\n",
            "🖥️ CUDA 사용 가능: False\n",
            "🍎 MPS 사용 가능: True\n",
            "✅ MPS 가속 사용!\n",
            "🎯 사용할 디바이스: mps\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(f\"🔥 PyTorch 버전: {torch.__version__}\")\n",
        "print(f\"🖥️ CUDA 사용 가능: {torch.cuda.is_available()}\")\n",
        "print(f\"🍎 MPS 사용 가능: {torch.backends.mps.is_available()}\")\n",
        "\n",
        "# Mac M1/M2의 경우 MPS 사용\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "    print(\"✅ MPS 가속 사용!\")\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"✅ CUDA 가속 사용!\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"⚠️ CPU 사용 (느릴 수 있음)\")\n",
        "\n",
        "print(f\"🎯 사용할 디바이스: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🧮 Step 2: Tensor 기본 연산\n",
        "\n",
        "Tensor는 NumPy array와 비슷하지만 **GPU에서 실행되고 자동 미분이 가능**합니다!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Tensor 생성 ====\n",
            "직접 생성: tensor([1., 2., 3., 4., 5.])\n",
            "\n",
            "0으로 초기화 (3x4):\n",
            "tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]])\n",
            "\n",
            "1로 초기화 (2x3):\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "\n",
            "랜덤 생성 (2x3):\n",
            "tensor([[ 0.3367,  0.1288,  0.2345],\n",
            "        [ 0.2303, -1.1229, -0.1863]])\n",
            "\n",
            "NumPy에서 변환:\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n"
          ]
        }
      ],
      "source": [
        "# 🔸 Tensor 생성 방법들\n",
        "print(\"=== Tensor 생성 ====\")\n",
        "\n",
        "# 1. 직접 생성\n",
        "x = torch.tensor([1, 2, 3, 4, 5], dtype=torch.float32)\n",
        "print(f\"직접 생성: {x}\")\n",
        "\n",
        "# 2. 0으로 초기화\n",
        "zeros = torch.zeros(3, 4)\n",
        "print(f\"\\n0으로 초기화 (3x4):\\n{zeros}\")\n",
        "\n",
        "# 3. 1로 초기화\n",
        "ones = torch.ones(2, 3)\n",
        "print(f\"\\n1로 초기화 (2x3):\\n{ones}\")\n",
        "\n",
        "# 4. 랜덤 생성\n",
        "torch.manual_seed(42)  # 재현 가능한 결과\n",
        "random = torch.randn(2, 3)  # 정규분포\n",
        "print(f\"\\n랜덤 생성 (2x3):\\n{random}\")\n",
        "\n",
        "# 5. NumPy에서 변환\n",
        "np_array = np.array([[1, 2], [3, 4]])\n",
        "from_numpy = torch.from_numpy(np_array).float()\n",
        "print(f\"\\nNumPy에서 변환:\\n{from_numpy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Tensor 연산 ====\n",
            "a:\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n",
            "\n",
            "b:\n",
            "tensor([[5., 6.],\n",
            "        [7., 8.]])\n",
            "\n",
            "a + b:\n",
            "tensor([[ 6.,  8.],\n",
            "        [10., 12.]])\n",
            "\n",
            "a @ b (행렬곱):\n",
            "tensor([[19., 22.],\n",
            "        [43., 50.]])\n",
            "\n",
            "a * b (원소별):\n",
            "tensor([[ 5., 12.],\n",
            "        [21., 32.]])\n",
            "\n",
            "a 전치:\n",
            "tensor([[1., 3.],\n",
            "        [2., 4.]])\n"
          ]
        }
      ],
      "source": [
        "# 🔸 Tensor 연산 (NumPy와 거의 동일!)\n",
        "print(\"=== Tensor 연산 ====\")\n",
        "\n",
        "a = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
        "b = torch.tensor([[5, 6], [7, 8]], dtype=torch.float32)\n",
        "\n",
        "print(f\"a:\\n{a}\")\n",
        "print(f\"\\nb:\\n{b}\")\n",
        "\n",
        "# 덧셈\n",
        "add_result = a + b\n",
        "print(f\"\\na + b:\\n{add_result}\")\n",
        "\n",
        "# 행렬 곱셈\n",
        "matmul_result = torch.matmul(a, b)\n",
        "print(f\"\\na @ b (행렬곱):\\n{matmul_result}\")\n",
        "\n",
        "# 원소별 곱셈\n",
        "mul_result = a * b\n",
        "print(f\"\\na * b (원소별):\\n{mul_result}\")\n",
        "\n",
        "# 전치\n",
        "transpose_result = a.T\n",
        "print(f\"\\na 전치:\\n{transpose_result}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🧠 Step 3: autograd - 자동 미분의 마법!\n",
        "\n",
        "PyTorch의 **핵심 기능**! 복잡한 함수도 자동으로 미분해줍니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== autograd 기초 ====\n",
            "x = 2.0\n",
            "y = x² + 3x + 1 = 11.0\n",
            "dy/dx = 7.0\n",
            "수학적 계산: 2*2.0 + 3 = 7.0\n",
            "✅ 일치!\n"
          ]
        }
      ],
      "source": [
        "# 🔸 requires_grad=True로 미분 추적 시작\n",
        "print(\"=== autograd 기초 ====\")\n",
        "\n",
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "print(f\"x = {x}\")\n",
        "\n",
        "# 함수 정의: y = x^2 + 3x + 1\n",
        "y = x**2 + 3*x + 1\n",
        "print(f\"y = x² + 3x + 1 = {y}\")\n",
        "\n",
        "# 자동 미분! dy/dx = 2x + 3\n",
        "y.backward()\n",
        "print(f\"dy/dx = {x.grad}\")\n",
        "print(f\"수학적 계산: 2*{x.item()} + 3 = {2*x.item() + 3}\")\n",
        "print(\"✅ 일치!\" if x.grad == 2*x.item() + 3 else \"❌ 불일치\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🚀 Step 4: 첫 번째 신경망 - Linear Regression\n",
        "\n",
        "드디어! **진짜 AI 모델**을 만들어봅시다!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== 첫 번째 신경망: Linear Regression ====\n",
            "데이터 모양: x=torch.Size([100, 1]), y=torch.Size([100, 1])\n",
            "실제 공식: y = 2x + 1\n",
            "\n",
            "모델 구조:\n",
            "LinearModel(\n",
            "  (linear): Linear(in_features=1, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            "초기 파라미터:\n",
            "linear.weight: tensor([[0.4801]])\n",
            "linear.bias: tensor([0.8415])\n"
          ]
        }
      ],
      "source": [
        "# 🔸 데이터 생성 및 신경망 정의\n",
        "print(\"=== 첫 번째 신경망: Linear Regression ====\")\n",
        "\n",
        "# 가짜 데이터 생성: y = 2x + 1 + noise\n",
        "torch.manual_seed(42)  # 재현 가능한 결과\n",
        "x_data = torch.randn(100, 1)  # 100개 샘플, 1차원\n",
        "y_data = 2 * x_data + 1 + 0.1 * torch.randn(100, 1)  # 노이즈 추가\n",
        "\n",
        "print(f\"데이터 모양: x={x_data.shape}, y={y_data.shape}\")\n",
        "print(f\"실제 공식: y = 2x + 1\")\n",
        "\n",
        "# 신경망 정의\n",
        "class LinearModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(1, 1)  # 입력 1차원 → 출력 1차원\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "# 모델 생성\n",
        "model = LinearModel()\n",
        "print(f\"\\n모델 구조:\\n{model}\")\n",
        "\n",
        "# 초기 파라미터 확인\n",
        "print(\"\\n초기 파라미터:\")\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"{name}: {param.data}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== 훈련 시작! ====\n",
            "Epoch  20: Loss = 0.0085\n",
            "Epoch  40: Loss = 0.0078\n",
            "Epoch  60: Loss = 0.0078\n",
            "Epoch  80: Loss = 0.0078\n",
            "Epoch 100: Loss = 0.0078\n",
            "\n",
            "✅ 훈련 완료!\n"
          ]
        }
      ],
      "source": [
        "# 🔸 훈련 설정 및 실행\n",
        "criterion = nn.MSELoss()  # Mean Squared Error\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)  # Stochastic Gradient Descent\n",
        "\n",
        "print(\"=== 훈련 시작! ====\")\n",
        "losses = []\n",
        "\n",
        "for epoch in range(100):\n",
        "    # Forward pass\n",
        "    predictions = model(x_data)\n",
        "    loss = criterion(predictions, y_data)\n",
        "    \n",
        "    # Backward pass\n",
        "    optimizer.zero_grad()  # 기울기 초기화\n",
        "    loss.backward()        # 역전파\n",
        "    optimizer.step()       # 파라미터 업데이트\n",
        "    \n",
        "    losses.append(loss.item())\n",
        "    \n",
        "    if (epoch + 1) % 20 == 0:\n",
        "        print(f\"Epoch {epoch+1:3d}: Loss = {loss.item():.4f}\")\n",
        "\n",
        "print(\"\\n✅ 훈련 완료!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== 학습된 파라미터 ====\n",
            "linear.weight: 2.001\n",
            "linear.bias: 1.004\n",
            "\n",
            "학습된 공식: y = 2.001x + 1.004\n",
            "실제 공식:   y = 2.000x + 1.000\n",
            "오차: weight=0.001, bias=0.004\n",
            "🎉 성공! AI가 올바른 패턴을 학습했습니다!\n",
            "\n",
            "=== Phase 1 vs Phase 2 비교 ===\n",
            "scikit-learn: y = 2.001x + 1.004\n",
            "PyTorch:      y = 2.001x + 1.004\n",
            "✅ 거의 동일한 성능!\n"
          ]
        }
      ],
      "source": [
        "# 🔸 결과 확인 및 성능 평가\n",
        "print(\"=== 학습된 파라미터 ====\")\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"{name}: {param.data.item():.3f}\")\n",
        "\n",
        "weight = model.linear.weight.data.item()\n",
        "bias = model.linear.bias.data.item()\n",
        "print(f\"\\n학습된 공식: y = {weight:.3f}x + {bias:.3f}\")\n",
        "print(f\"실제 공식:   y = 2.000x + 1.000\")\n",
        "print(f\"오차: weight={abs(weight-2):.3f}, bias={abs(bias-1):.3f}\")\n",
        "\n",
        "if abs(weight-2) < 0.1 and abs(bias-1) < 0.1:\n",
        "    print(\"🎉 성공! AI가 올바른 패턴을 학습했습니다!\")\n",
        "else:\n",
        "    print(\"🤔 더 훈련이 필요할 수도...\")\n",
        "\n",
        "# Phase 1과 비교\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "sklearn_model = LinearRegression()\n",
        "sklearn_model.fit(x_data.numpy(), y_data.numpy())\n",
        "\n",
        "print(f\"\\n=== Phase 1 vs Phase 2 비교 ===\")\n",
        "print(f\"scikit-learn: y = {sklearn_model.coef_[0][0]:.3f}x + {sklearn_model.intercept_[0]:.3f}\")\n",
        "print(f\"PyTorch:      y = {weight:.3f}x + {bias:.3f}\")\n",
        "print(\"✅ 거의 동일한 성능!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🏆 Week 1 Day 1 완료!\n",
        "\n",
        "### ✅ **오늘의 성과:**\n",
        "\n",
        "1. **🔥 PyTorch 2.8.0** 설치 완료\n",
        "2. **🍎 MPS 가속** 활성화 (Mac 최적화!)  \n",
        "3. **🧮 Tensor 연산** 마스터\n",
        "4. **🧠 autograd** 자동 미분 이해\n",
        "5. **🚀 첫 신경망** Linear Regression 구현\n",
        "\n",
        "### 📊 **AI 학습 결과:**\n",
        "```\n",
        "실제 공식:   y = 2.000x + 1.000\n",
        "AI 학습 결과: y = 2.001x + 1.004\n",
        "오차: 0.1% 미만! 🎯\n",
        "```\n",
        "\n",
        "### 🎯 **다음 단계:**\n",
        "- **02_neural_networks.ipynb**: 분류 신경망\n",
        "- **03_cnn_basics.ipynb**: 이미지 처리 CNN  \n",
        "- **04_cifar10_project.ipynb**: 실전 이미지 분류\n",
        "\n",
        "---\n",
        "\n",
        "## 💡 **Phase 1 → Phase 2 업그레이드 완료!**\n",
        "\n",
        "| scikit-learn (Phase 1) | PyTorch (Phase 2) |\n",
        "|------------------------|-------------------|\n",
        "| 🔸 간단한 분류/회귀 | 🔥 복잡한 딥러닝 |\n",
        "| 🔸 CPU만 사용 | 🔥 GPU/MPS 가속 |\n",
        "| 🔸 고정된 알고리즘 | 🔥 무한한 확장성 |\n",
        "\n",
        "🎉 **축하합니다! 이제 진짜 AI 개발자의 첫 걸음을 완료했습니다!**\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
