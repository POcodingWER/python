{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🤖 AI 기초 완전 정리 가이드\n",
        "\n",
        "## 🎯 \"2주 동안 뭘 배웠나?\" 한 눈에 보기\n",
        "\n",
        "**진짜 쉽게 설명하는 AI 기초 총정리!** 🍯\n",
        "\n",
        "---\n",
        "\n",
        "## 📋 목차\n",
        "\n",
        "1. **AI 알고리즘 3대장** - Decision Tree, Random Forest, SVM\n",
        "2. **분류 vs 회귀** - 뭐가 다른가?\n",
        "3. **모델 평가 방법** - train_test_split vs cross_validation\n",
        "4. **평가 지표 총정리** - 정확도, 정밀도, 재현율 등\n",
        "5. **scikit-learn 사용법** - fit, predict 패턴\n",
        "6. **실전 팁** - 언제 뭘 써야 하나?\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 🤖 AI 알고리즘 3대장\n",
        "\n",
        "### 🌳 Decision Tree (의사결정나무)\n",
        "```\n",
        "장점: 해석하기 쉬움 (if-else 규칙)\n",
        "단점: 과적합 위험 높음\n",
        "언제 쓸까: 결과를 설명해야 할 때\n",
        "```\n",
        "\n",
        "### 🌲 Random Forest (랜덤포레스트) \n",
        "```\n",
        "장점: 성능 좋고 안정적\n",
        "단점: 해석하기 어려움\n",
        "언제 쓸까: 성능이 중요할 때 (보통 이걸로 시작)\n",
        "```\n",
        "\n",
        "### 🎯 SVM (서포트벡터머신)\n",
        "```\n",
        "장점: 소량 데이터에서도 잘 작동\n",
        "단점: 큰 데이터에서는 느림\n",
        "언제 쓸까: 데이터가 적을 때\n",
        "```\n",
        "\n",
        "**💡 결론: 일단 Random Forest부터 시작해라!** 🏆\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🤖 3개 알고리즘 성능 대결!\n",
            "========================================\n",
            "🌳 Decision Tree: 1.000 (100.0%)\n",
            "🌲 Random Forest: 1.000 (100.0%)\n",
            "🎯 SVM: 1.000 (100.0%)\n",
            "\n",
            "🏆 승자: Decision Tree!\n",
            "💡 보통 Random Forest가 안정적으로 좋은 성능을 냅니다!\n"
          ]
        }
      ],
      "source": [
        "# 🔥 알고리즘 3개 실제 코드로 보기!\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier  \n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 데이터 준비\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"🤖 3개 알고리즘 성능 대결!\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# 1. Decision Tree\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "dt_score = accuracy_score(y_test, dt.predict(X_test))\n",
        "print(f\"🌳 Decision Tree: {dt_score:.3f} ({dt_score*100:.1f}%)\")\n",
        "\n",
        "# 2. Random Forest  \n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "rf_score = accuracy_score(y_test, rf.predict(X_test))\n",
        "print(f\"🌲 Random Forest: {rf_score:.3f} ({rf_score*100:.1f}%)\")\n",
        "\n",
        "# 3. SVM\n",
        "svm = SVC(random_state=42)\n",
        "svm.fit(X_train, y_train)\n",
        "svm_score = accuracy_score(y_test, svm.predict(X_test))\n",
        "print(f\"🎯 SVM: {svm_score:.3f} ({svm_score*100:.1f}%)\")\n",
        "\n",
        "# 승자 발표!\n",
        "scores = {'Decision Tree': dt_score, 'Random Forest': rf_score, 'SVM': svm_score}\n",
        "winner = max(scores, key=scores.get)\n",
        "print(f\"\\n🏆 승자: {winner}!\")\n",
        "print(\"💡 보통 Random Forest가 안정적으로 좋은 성능을 냅니다!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 🏷️ 분류 vs 회귀\n",
        "\n",
        "### 🏷️ 분류 (Classification)\n",
        "```\n",
        "뭘 하는가: 카테고리 예측\n",
        "예시:\n",
        "- 스팸 메일인가? (스팸/정상)\n",
        "- 어떤 꽃인가? (장미/튤립/국화)\n",
        "- 생존했나? (생존/사망)\n",
        "```\n",
        "\n",
        "### 📈 회귀 (Regression)\n",
        "```\n",
        "뭘 하는가: 숫자 예측\n",
        "예시:\n",
        "- 집값은 얼마? (3억 5천만원)\n",
        "- 내일 기온은? (25.3도)\n",
        "- 매출은 얼마? (1억 2천만원)\n",
        "```\n",
        "\n",
        "**💡 구분법: 답이 카테고리면 분류, 연속된 숫자면 회귀!** 📊\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏷️ 분류 예제 - 아이리스 꽃 분류\n",
            "==================================================\n",
            "예측된 꽃 종류: setosa\n",
            "답: 카테고리 (0, 1, 2 중 하나)\n",
            "\n",
            "📈 회귀 예제 - 간단한 수치 예측\n",
            "==================================================\n",
            "집 크기에 따른 가격 예측 모델!\n",
            "🏠 65평 집 예측 가격: 5.15억원\n",
            "답: 연속된 숫자 (예: 5.12억, 6.73억, 4.88억...)\n",
            "\n",
            "📊 다양한 크기별 예측:\n",
            "   45평 → 3.64억원\n",
            "   75평 → 5.90억원\n",
            "   85평 → 6.66억원\n",
            "\n",
            "💡 핵심 차이점:\n",
            "🏷️ 분류: 답이 정해진 카테고리 (setosa, versicolor, virginica)\n",
            "📈 회귀: 답이 연속된 숫자 (5.12억, 6.73억, 4.88억...)\n",
            "🎯 쉽게 말해: 분류는 '종류 맞추기', 회귀는 '값 예측하기'!\n"
          ]
        }
      ],
      "source": [
        "# 🎯 분류 vs 회귀 실제 코드로 보기!\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "print(\"🏷️ 분류 예제 - 아이리스 꽃 분류\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# 분류: 아이리스 꽃 종류 예측 (setosa, versicolor, virginica)\n",
        "iris = load_iris()\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "rf_classifier.fit(iris.data, iris.target)\n",
        "\n",
        "# 새로운 꽃 하나 예측해보기\n",
        "new_flower = [[5.1, 3.5, 1.4, 0.2]]  # 꽃잎, 꽃받침 크기\n",
        "prediction = rf_classifier.predict(new_flower)\n",
        "flower_names = ['setosa', 'versicolor', 'virginica']\n",
        "print(f\"예측된 꽃 종류: {flower_names[prediction[0]]}\")\n",
        "print(f\"답: 카테고리 (0, 1, 2 중 하나)\")\n",
        "\n",
        "print(\"\\n📈 회귀 예제 - 간단한 수치 예측\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# 회귀: 연속된 숫자 예측 (집값 대신 간단한 예제)\n",
        "print(\"집 크기에 따른 가격 예측 모델!\")\n",
        "\n",
        "# 집 크기(평수)와 가격 데이터 (가상 데이터)\n",
        "house_sizes = np.array([[30], [40], [50], [60], [70], [80], [90], [100]])  # 평수\n",
        "house_prices = np.array([2.5, 3.2, 4.1, 4.8, 5.5, 6.3, 7.0, 7.8])  # 억원\n",
        "\n",
        "# 회귀 모델 학습\n",
        "lr_regressor = LinearRegression()\n",
        "lr_regressor.fit(house_sizes, house_prices)\n",
        "\n",
        "# 새로운 집 크기로 가격 예측\n",
        "new_house_size = [[65]]  # 65평 집\n",
        "price_prediction = lr_regressor.predict(new_house_size)\n",
        "\n",
        "print(f\"🏠 65평 집 예측 가격: {price_prediction[0]:.2f}억원\")\n",
        "print(f\"답: 연속된 숫자 (예: 5.12억, 6.73억, 4.88억...)\")\n",
        "\n",
        "# 여러 크기 예측해보기\n",
        "test_sizes = [[45], [75], [85]]\n",
        "test_predictions = lr_regressor.predict(test_sizes)\n",
        "\n",
        "print(f\"\\n📊 다양한 크기별 예측:\")\n",
        "for size, price in zip(test_sizes, test_predictions):\n",
        "    print(f\"   {size[0]}평 → {price:.2f}억원\")\n",
        "\n",
        "print(\"\\n💡 핵심 차이점:\")\n",
        "print(\"🏷️ 분류: 답이 정해진 카테고리 (setosa, versicolor, virginica)\")\n",
        "print(\"📈 회귀: 답이 연속된 숫자 (5.12억, 6.73억, 4.88억...)\")\n",
        "print(\"🎯 쉽게 말해: 분류는 '종류 맞추기', 회귀는 '값 예측하기'!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 📊 모델 평가 방법 (이해 못했던 부분!)\n",
        "\n",
        "### 🔪 train_test_split (훈련/테스트 분할)\n",
        "```python\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# 8:2로 나누기\n",
        "# 80% = 훈련용 (모델이 배우는 용도)\n",
        "# 20% = 테스트용 (모델 성능 확인용)\n",
        "```\n",
        "- **장점**: 간단함\n",
        "- **단점**: 운빨에 좌우될 수 있음 (좋은 데이터가 테스트에 몰릴 수도)\n",
        "\n",
        "### ✂️ Cross Validation (교차검증)\n",
        "```python\n",
        "scores = cross_val_score(model, X, y, cv=5)\n",
        "# 5번 나눠서 5번 테스트해서 평균냄\n",
        "```\n",
        "- **장점**: 더 정확함 (여러 번 테스트)\n",
        "- **단점**: 시간 좀 더 걸림\n",
        "\n",
        "**💡 결론: 시간 여유 있으면 CV, 빠르게 하려면 train_test_split!** ⚡\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔪 방법 1: train_test_split (한 번만 나누기)\n",
            "============================================================\n",
            "한 번 테스트 결과: 1.000 (100.0%)\n",
            "\n",
            "✂️ 방법 2: Cross Validation (5번 나누기)\n",
            "============================================================\n",
            "1번째 테스트: 0.967 (96.7%)\n",
            "2번째 테스트: 0.967 (96.7%)\n",
            "3번째 테스트: 0.933 (93.3%)\n",
            "4번째 테스트: 0.967 (96.7%)\n",
            "5번째 테스트: 1.000 (100.0%)\n",
            "\n",
            "평균 성능: 0.967 ± 0.021\n",
            "→ 96.7% (± 2.1%)\n",
            "\n",
            "💡 왜 Cross Validation이 더 좋은가?\n",
            "단일 테스트: 100.0% (운에 좌우될 수 있음)\n",
            "교차 검증: 96.7% ± 2.1% (더 신뢰할 만함)\n",
            "\n",
            "🎯 결론: CV가 더 정확하지만, 빠르게 확인하려면 train_test_split도 OK!\n"
          ]
        }
      ],
      "source": [
        "# 📊 모델 평가 방법 2가지 실제 비교!\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "print(\"🔪 방법 1: train_test_split (한 번만 나누기)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 데이터 준비\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# 방법 1: train_test_split (한 번만 나누기)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "single_score = accuracy_score(y_test, rf.predict(X_test))\n",
        "print(f\"한 번 테스트 결과: {single_score:.3f} ({single_score*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\n✂️ 방법 2: Cross Validation (5번 나누기)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 방법 2: Cross Validation (5번 나누기)\n",
        "rf_cv = RandomForestClassifier(random_state=42)\n",
        "cv_scores = cross_val_score(rf_cv, X, y, cv=5)  # 5번 나누기\n",
        "\n",
        "print(f\"1번째 테스트: {cv_scores[0]:.3f} ({cv_scores[0]*100:.1f}%)\")\n",
        "print(f\"2번째 테스트: {cv_scores[1]:.3f} ({cv_scores[1]*100:.1f}%)\")\n",
        "print(f\"3번째 테스트: {cv_scores[2]:.3f} ({cv_scores[2]*100:.1f}%)\")\n",
        "print(f\"4번째 테스트: {cv_scores[3]:.3f} ({cv_scores[3]*100:.1f}%)\")\n",
        "print(f\"5번째 테스트: {cv_scores[4]:.3f} ({cv_scores[4]*100:.1f}%)\")\n",
        "\n",
        "cv_mean = cv_scores.mean()\n",
        "cv_std = cv_scores.std()\n",
        "print(f\"\\n평균 성능: {cv_mean:.3f} ± {cv_std:.3f}\")\n",
        "print(f\"→ {cv_mean*100:.1f}% (± {cv_std*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\n💡 왜 Cross Validation이 더 좋은가?\")\n",
        "print(f\"단일 테스트: {single_score*100:.1f}% (운에 좌우될 수 있음)\")\n",
        "print(f\"교차 검증: {cv_mean*100:.1f}% ± {cv_std*100:.1f}% (더 신뢰할 만함)\")\n",
        "print(f\"\\n🎯 결론: CV가 더 정확하지만, 빠르게 확인하려면 train_test_split도 OK!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 📈 평가 지표 총정리 (어떻게 봐야 되는지 모르겠던 부분!)\n",
        "\n",
        "### 🎯 정확도 (Accuracy)\n",
        "```\n",
        "전체 중에 맞춘 비율\n",
        "정확도 = (맞춘 개수) / (전체 개수)\n",
        "예: 100개 중 85개 맞춤 → 85%\n",
        "```\n",
        "\n",
        "### 🔍 정밀도 (Precision)\n",
        "```\n",
        "\"생존\"이라고 예측한 것 중에 실제로 생존한 비율\n",
        "정밀도 = (진짜 생존자) / (생존 예측 전체)\n",
        "예: 생존 예측 50명 중 실제 생존 40명 → 80%\n",
        "```\n",
        "\n",
        "### 🎣 재현율 (Recall)\n",
        "```\n",
        "실제 생존자 중에 모델이 찾아낸 비율\n",
        "재현율 = (찾아낸 생존자) / (실제 생존자 전체)\n",
        "예: 실제 생존자 60명 중 40명 찾음 → 67%\n",
        "```\n",
        "\n",
        "### 📊 혼동행렬 (Confusion Matrix)\n",
        "```\n",
        "실제 vs 예측 비교표\n",
        "         예측\n",
        "실제   생존  사망\n",
        "생존   40   20   ← 생존자 60명 중 40명 맞춤\n",
        "사망   10   30   ← 사망자 40명 중 30명 맞춤\n",
        "```\n",
        "\n",
        "**💡 언제 뭘 봐야 하나?**\n",
        "- **정확도**: 전체적으로 잘하나?\n",
        "- **정밀도**: 거짓양성(False Positive) 줄이고 싶을 때\n",
        "- **재현율**: 놓치는 거(False Negative) 줄이고 싶을 때\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 평가지표 완전 해부!\n",
            "==================================================\n",
            "🎯 정확도: 1.000 (100.0%)\n",
            "   → 전체 45개 중 45개 맞춤\n",
            "\n",
            "📊 혼동행렬:\n",
            "실제\\예측  [0]  [1]\n",
            "   [0]     26   0\n",
            "   [1]      0  19\n",
            "\n",
            "🔍 혼동행렬 해석:\n",
            "   TN (True Negative): 26개 - 진짜로 '아님'을 맞춤\n",
            "   FP (False Positive): 0개 - '그렇다'고 잘못 예측\n",
            "   FN (False Negative): 0개 - '아니다'라고 잘못 예측\n",
            "   TP (True Positive): 19개 - 진짜로 '맞음'을 맞춤\n",
            "\n",
            "🔍 정밀도: 1.000 (100.0%)\n",
            "   → '1'이라고 예측한 19개 중 19개가 진짜 맞음\n",
            "\n",
            "🎣 재현율: 1.000 (100.0%)\n",
            "   → 실제 '1'인 19개 중 19개를 찾아냄\n",
            "\n",
            "📋 전체 리포트:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Not Setosa       1.00      1.00      1.00        26\n",
            "      Setosa       1.00      1.00      1.00        19\n",
            "\n",
            "    accuracy                           1.00        45\n",
            "   macro avg       1.00      1.00      1.00        45\n",
            "weighted avg       1.00      1.00      1.00        45\n",
            "\n",
            "\n",
            "💡 실전 해석법:\n",
            "정확도 100.0%는 전체적으로 괜찮은 성능!\n",
            "재현율 > 정밀도 → 놓치지 않으려는 적극적 모델\n"
          ]
        }
      ],
      "source": [
        "# 📈 평가지표 실제로 계산해보기!\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, classification_report\n",
        "\n",
        "print(\"📊 평가지표 완전 해부!\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# 데이터 준비 (이진 분류로 만들기)\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# 2개 클래스로 만들기 (0 vs 나머지)\n",
        "y_binary = (y == 0).astype(int)  # setosa면 1, 아니면 0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.3, random_state=42)\n",
        "\n",
        "# 모델 학습\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "# 1. 정확도\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"🎯 정확도: {accuracy:.3f} ({accuracy*100:.1f}%)\")\n",
        "print(f\"   → 전체 {len(y_test)}개 중 {int(accuracy*len(y_test))}개 맞춤\")\n",
        "\n",
        "# 2. 혼동행렬\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(f\"\\n📊 혼동행렬:\")\n",
        "print(f\"실제\\\\예측  [0]  [1]\")\n",
        "print(f\"   [0]     {cm[0,0]:2d}  {cm[0,1]:2d}\")\n",
        "print(f\"   [1]     {cm[1,0]:2d}  {cm[1,1]:2d}\")\n",
        "\n",
        "# 혼동행렬 해석\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "print(f\"\\n🔍 혼동행렬 해석:\")\n",
        "print(f\"   TN (True Negative): {tn}개 - 진짜로 '아님'을 맞춤\")\n",
        "print(f\"   FP (False Positive): {fp}개 - '그렇다'고 잘못 예측\")\n",
        "print(f\"   FN (False Negative): {fn}개 - '아니다'라고 잘못 예측\")\n",
        "print(f\"   TP (True Positive): {tp}개 - 진짜로 '맞음'을 맞춤\")\n",
        "\n",
        "# 3. 정밀도와 재현율\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\n🔍 정밀도: {precision:.3f} ({precision*100:.1f}%)\")\n",
        "print(f\"   → '1'이라고 예측한 {tp+fp}개 중 {tp}개가 진짜 맞음\")\n",
        "\n",
        "print(f\"\\n🎣 재현율: {recall:.3f} ({recall*100:.1f}%)\")\n",
        "print(f\"   → 실제 '1'인 {tp+fn}개 중 {tp}개를 찾아냄\")\n",
        "\n",
        "print(f\"\\n📋 전체 리포트:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Not Setosa', 'Setosa']))\n",
        "\n",
        "print(f\"\\n💡 실전 해석법:\")\n",
        "print(f\"정확도 {accuracy*100:.1f}%는 전체적으로 괜찮은 성능!\")\n",
        "if precision > recall:\n",
        "    print(f\"정밀도 > 재현율 → 확실한 것만 예측하는 보수적 모델\")\n",
        "else:\n",
        "    print(f\"재현율 > 정밀도 → 놓치지 않으려는 적극적 모델\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 🔧 scikit-learn 사용법 (fit으로 학습시키고...)\n",
        "\n",
        "### 🔄 기본 패턴 (이것만 외우면 됨!)\n",
        "```python\n",
        "# 1. 모델 생성\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "# 2. 학습 (fit)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 3. 예측 (predict)\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# 4. 평가\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "```\n",
        "\n",
        "### 📈 확률까지 보고 싶다면\n",
        "```python\n",
        "probabilities = model.predict_proba(X_test)\n",
        "# [[0.2, 0.8], [0.9, 0.1]] → 첫번째: 20% 생존, 두번째: 90% 생존\n",
        "```\n",
        "\n",
        "**💡 이 패턴만 기억하면 어떤 알고리즘이든 똑같이 쓸 수 있음!** 🎯\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔧 scikit-learn 만능 패턴!\n",
            "==================================================\n",
            "모든 알고리즘이 똑같은 패턴으로 작동!\n",
            "--------------------------------------------------\n",
            "\n",
            "🤖 Decision Tree 테스트:\n",
            "   1. 모델 생성 ✓\n",
            "   2. 학습 완료 ✓\n",
            "   3. 예측 완료 ✓\n",
            "   4. 정확도: 1.000 (100.0%) ✓\n",
            "   5. 확률 예측: [0. 1. 0.] (첫 번째 샘플)\n",
            "\n",
            "🤖 Random Forest 테스트:\n",
            "   1. 모델 생성 ✓\n",
            "   2. 학습 완료 ✓\n",
            "   3. 예측 완료 ✓\n",
            "   4. 정확도: 1.000 (100.0%) ✓\n",
            "   5. 확률 예측: [0.   0.99 0.01] (첫 번째 샘플)\n",
            "\n",
            "🤖 SVM 테스트:\n",
            "   1. 모델 생성 ✓\n",
            "   2. 학습 완료 ✓\n",
            "   3. 예측 완료 ✓\n",
            "   4. 정확도: 1.000 (100.0%) ✓\n",
            "   5. 확률 예측: [0.006677   0.89799557 0.09532743] (첫 번째 샘플)\n",
            "\n",
            "💡 핵심 포인트:\n",
            "   📌 모든 알고리즘: model.fit() → model.predict() 패턴 동일!\n",
            "   📌 바꾸고 싶으면 모델만 바꾸면 됨!\n",
            "   📌 RandomForestClassifier() → DecisionTreeClassifier() 이런 식으로!\n",
            "\n",
            "🌸 실전 예제: 새로운 꽃 예측하기\n",
            "==================================================\n",
            "🔮 예측 결과: setosa\n",
            "📊 확률: [1. 0. 0.]\n",
            "   - setosa: 100.0%\n",
            "   - versicolor: 0.0%\n",
            "   - virginica: 0.0%\n",
            "\n",
            "🎯 이 패턴만 기억하면 어떤 데이터든 분석 가능!\n"
          ]
        }
      ],
      "source": [
        "# 🔧 scikit-learn 만능 패턴 실습!\n",
        "print(\"🔧 scikit-learn 만능 패턴!\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# 어떤 알고리즘이든 패턴은 동일!\n",
        "algorithms = {\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'SVM': SVC(random_state=42, probability=True)  # probability=True로 확률 예측 가능\n",
        "}\n",
        "\n",
        "# 데이터 준비\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"모든 알고리즘이 똑같은 패턴으로 작동!\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "for name, model in algorithms.items():\n",
        "    print(f\"\\n🤖 {name} 테스트:\")\n",
        "    \n",
        "    # 1. 모델 생성 (이미 위에서 함)\n",
        "    print(\"   1. 모델 생성 ✓\")\n",
        "    \n",
        "    # 2. 학습 (fit) - 모든 알고리즘 동일!\n",
        "    model.fit(X_train, y_train)\n",
        "    print(\"   2. 학습 완료 ✓\")\n",
        "    \n",
        "    # 3. 예측 (predict) - 모든 알고리즘 동일!\n",
        "    predictions = model.predict(X_test)\n",
        "    print(\"   3. 예측 완료 ✓\")\n",
        "    \n",
        "    # 4. 평가 - 모든 알고리즘 동일!\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    print(f\"   4. 정확도: {accuracy:.3f} ({accuracy*100:.1f}%) ✓\")\n",
        "    \n",
        "    # 5. 확률 예측 (선택사항)\n",
        "    if hasattr(model, 'predict_proba'):\n",
        "        probabilities = model.predict_proba(X_test)\n",
        "        print(f\"   5. 확률 예측: {probabilities[0]} (첫 번째 샘플)\")\n",
        "\n",
        "print(f\"\\n💡 핵심 포인트:\")\n",
        "print(f\"   📌 모든 알고리즘: model.fit() → model.predict() 패턴 동일!\")\n",
        "print(f\"   📌 바꾸고 싶으면 모델만 바꾸면 됨!\")\n",
        "print(f\"   📌 RandomForestClassifier() → DecisionTreeClassifier() 이런 식으로!\")\n",
        "\n",
        "# 실전 예제: 새로운 꽃 예측해보기\n",
        "print(f\"\\n🌸 실전 예제: 새로운 꽃 예측하기\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "new_flower = [[5.1, 3.5, 1.4, 0.2]]  # 새로운 꽃 데이터\n",
        "best_model = RandomForestClassifier(random_state=42)\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "prediction = best_model.predict(new_flower)\n",
        "probability = best_model.predict_proba(new_flower)\n",
        "\n",
        "flower_names = ['setosa', 'versicolor', 'virginica']\n",
        "print(f\"🔮 예측 결과: {flower_names[prediction[0]]}\")\n",
        "print(f\"📊 확률: {probability[0]}\")\n",
        "print(f\"   - setosa: {probability[0][0]:.1%}\")\n",
        "print(f\"   - versicolor: {probability[0][1]:.1%}\")  \n",
        "print(f\"   - virginica: {probability[0][2]:.1%}\")\n",
        "\n",
        "print(f\"\\n🎯 이 패턴만 기억하면 어떤 데이터든 분석 가능!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 🎯 실전 팁 (언제 뭘 써야 하나?)\n",
        "\n",
        "### 🚀 처음 시작할 때\n",
        "1. **Random Forest**부터 시작 (성능 좋음)\n",
        "2. **train_test_split**으로 빠르게 테스트\n",
        "3. **정확도**만 일단 봐도 OK\n",
        "\n",
        "### 📊 좀 더 정교하게 하고 싶을 때\n",
        "1. **Cross Validation**으로 평가\n",
        "2. **정밀도, 재현율**까지 확인\n",
        "3. **혼동행렬**로 어디서 틀렸는지 분석\n",
        "\n",
        "### 🎯 알고리즘 선택 가이드\n",
        "```\n",
        "데이터 크기가 작다 → SVM\n",
        "설명 가능해야 한다 → Decision Tree\n",
        "성능이 중요하다 → Random Forest\n",
        "```\n",
        "\n",
        "### 🔧 문제 해결 순서\n",
        "```\n",
        "1. 데이터 로드\n",
        "2. 탐색적 분석 (EDA)\n",
        "3. 전처리 (결측치, 인코딩)\n",
        "4. 모델 학습\n",
        "5. 평가\n",
        "6. 개선\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎉 AI 기초 2주 완전 정복 요약!\n",
            "============================================================\n",
            "✅ 학습 완료 항목들:\n",
            "   🤖 AI 알고리즘 3대장 정복\n",
            "      → Decision Tree, Random Forest, SVM 특징과 사용법\n",
            "   🏷️ 분류 vs 회귀 완벽 이해\n",
            "      → 카테고리 예측 vs 숫자 예측\n",
            "   📊 모델 평가 방법 2가지 습득\n",
            "      → train_test_split vs Cross Validation\n",
            "   📈 평가 지표 해석 능력 획득\n",
            "      → 정확도, 정밀도, 재현율, 혼동행렬\n",
            "   🔧 scikit-learn 패턴 완전 정복\n",
            "      → fit() → predict() 만능 패턴\n",
            "\n",
            "🏆 달성한 프로젝트:\n",
            "   📊 아이리스 꽃 분류 (3개 알고리즘 비교)\n",
            "   🚢 타이타닉 생존 예측 (정확도 81.6%)\n",
            "   📈 회귀 알고리즘 3개 비교\n",
            "   🔍 평가 지표 완전 분석\n",
            "\n",
            "💡 핵심 깨달음:\n",
            "   1. 일단 Random Forest부터! (성능 좋고 안정적)\n",
            "   2. 모든 알고리즘은 fit() → predict() 패턴 동일!\n",
            "   3. 정확도만 봐도 시작으로는 충분!\n",
            "   4. Cross Validation이 더 정확하지만 빠르게는 train_test_split!\n",
            "\n",
            "🚀 다음 단계:\n",
            "   📚 Week 5-8: 암호학 기초\n",
            "   🔐 해시 함수, 공개키 암호, ZKP 개념\n",
            "   🎯 ZKML로 가는 첫 번째 스텝!\n",
            "\n",
            "🎓 축하합니다!\n",
            "AI 기초를 완전 정복하셨습니다! 🎉\n",
            "이제 어떤 데이터든 머신러닝으로 분석할 수 있어요!\n",
            "\n",
            "============================================================\n",
            "'AI는 어렵지 않다. 패턴만 익히면 된다!' 💪\n",
            "'fit으로 학습시키고 predict로 예측한다!' 🎯\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# 🎉 2주 완전 정복 요약!\n",
        "print(\"🎉 AI 기초 2주 완전 정복 요약!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"✅ 학습 완료 항목들:\")\n",
        "print(\"   🤖 AI 알고리즘 3대장 정복\")\n",
        "print(\"      → Decision Tree, Random Forest, SVM 특징과 사용법\")\n",
        "print(\"   🏷️ 분류 vs 회귀 완벽 이해\")\n",
        "print(\"      → 카테고리 예측 vs 숫자 예측\")\n",
        "print(\"   📊 모델 평가 방법 2가지 습득\")\n",
        "print(\"      → train_test_split vs Cross Validation\")\n",
        "print(\"   📈 평가 지표 해석 능력 획득\")\n",
        "print(\"      → 정확도, 정밀도, 재현율, 혼동행렬\")\n",
        "print(\"   🔧 scikit-learn 패턴 완전 정복\")\n",
        "print(\"      → fit() → predict() 만능 패턴\")\n",
        "\n",
        "print(f\"\\n🏆 달성한 프로젝트:\")\n",
        "print(f\"   📊 아이리스 꽃 분류 (3개 알고리즘 비교)\")\n",
        "print(f\"   🚢 타이타닉 생존 예측 (정확도 81.6%)\")\n",
        "print(f\"   📈 회귀 알고리즘 3개 비교\")\n",
        "print(f\"   🔍 평가 지표 완전 분석\")\n",
        "\n",
        "print(f\"\\n💡 핵심 깨달음:\")\n",
        "print(f\"   1. 일단 Random Forest부터! (성능 좋고 안정적)\")\n",
        "print(f\"   2. 모든 알고리즘은 fit() → predict() 패턴 동일!\")\n",
        "print(f\"   3. 정확도만 봐도 시작으로는 충분!\")\n",
        "print(f\"   4. Cross Validation이 더 정확하지만 빠르게는 train_test_split!\")\n",
        "\n",
        "print(f\"\\n🚀 다음 단계:\")\n",
        "print(f\"   📚 Week 5-8: 암호학 기초\")\n",
        "print(f\"   🔐 해시 함수, 공개키 암호, ZKP 개념\")\n",
        "print(f\"   🎯 ZKML로 가는 첫 번째 스텝!\")\n",
        "\n",
        "print(f\"\\n🎓 축하합니다!\")\n",
        "print(f\"AI 기초를 완전 정복하셨습니다! 🎉\")\n",
        "print(f\"이제 어떤 데이터든 머신러닝으로 분석할 수 있어요!\")\n",
        "\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(f\"'AI는 어렵지 않다. 패턴만 익히면 된다!' 💪\")\n",
        "print(f\"'fit으로 학습시키고 predict로 예측한다!' 🎯\")\n",
        "print(f\"=\" * 60)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
